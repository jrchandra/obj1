{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Evaluation Notebook\n",
    "This notebook demonstrates how to evaluate machine translation output using BLEU, CHRF++, TER, METEOR, and COMET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install sacrebleu unbabel-comet nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sacrebleu\n",
    "from comet import download_model, load_from_checkpoint\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "sources = ["This is a test.", "How are you?"]\n",
    "references = ["Oqo e dua na vakatovolea.", "Vakacava o iko?"]\n",
    "hypotheses = ["Oqo e dua na vakatovolea.", "O iko vakacava?"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU\n",
    "bleu = sacrebleu.corpus_bleu(hypotheses, [references])\n",
    "print("BLEU:", bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHRF++\n",
    "chrf = sacrebleu.corpus_chrf(hypotheses, [references])\n",
    "print("CHRF++:", chrf.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TER\n",
    "ter = sacrebleu.corpus_ter(hypotheses, [references])\n",
    "print("TER:", ter.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METEOR (avg over all pairs)\n",
    "meteor_scores = [meteor_score([ref], hyp) for ref, hyp in zip(references, hypotheses)]\n",
    "print("METEOR:", sum(meteor_scores) / len(meteor_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMET\n",
    "model_path = download_model("Unbabel/wmt22-comet-da")\n",
    "model = load_from_checkpoint(model_path)\n",
    "data = [{"src": src, "mt": hyp, "ref": ref} for src, hyp, ref in zip(sources, hypotheses, references)]\n",
    "comet_score = model.predict(data, batch_size=8, gpus=1 if model.hparams.gpus > 0 else 0)\n",
    "print("COMET:", comet_score.system_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
